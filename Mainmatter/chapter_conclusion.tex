\chapter{Conclusion}
\label{cha:conclusion}

\begin{chapterabstract}
This last chapter of the thesis presents the final conclusions of this work. Firstly, Section \ref{cha:conclusion:sec:findings} presents the general conclusions of the work. Next, Section \ref{cha:conclusion:sec:contributions} goes through the major findings. At last, Section \ref{cha:conclusion:sec:future} concludes this thesis by listing the limitations of each one of the chapters in this thesis and also lists a set of possible future lines of research.
\end{chapterabstract}

\minitoc

\clearpage

\section{Conclusions}
\label{cha:conclusion:sec:findings}

In this thesis, we have explored four core problems for indoor robotics with a heavy emphasis on computer vision. However, despite the obvious differences and the distance between each topic, we can extract certain general conclusions.

First and foremost, after reviewing the state of the art of each of the topics of this thesis, we can state that deep learning has secured solid ground to be considered the \emph{de facto} paradigm for solving computer vision and robotics problems. In almost every aspect, deep learning architectures outperform traditional hand-engineered approaches.

A general observation across all problems is the fact that \ac{3D} representations offer useful information that is clearly beneficial for learning models with better generalization capabilities. However, to take full advantage of three-dimensional information, network architectures need to properly take into account the spatial arrangement and the unstructured nature of \ac{3D} data.

Following on the last observation, we also experienced the difficulties of training models for three-dimensional data. That additional dimension poses various challenges that range from memory footprint to increased execution time and also harder training prone to overfitting. In that regard, in order to ensure generalization, more quantity and more varied data is needed.

It is exactly at this spot where synthetic data generation is proven to be an extremely valuable tool to avoid the cost and errors of manually generated datasets. However, they still have to deal with problems of their own, mainly the transfer of the knowledge acquired in the synthetic domain to the real-world.

\section{Contributions}
\label{cha:conclusion:sec:contributions}

Once we have stated the general conclusions of the thesis, we briefly summarize the main contributions and findings.

Chapter \ref{cha:objrecog} introduced a set of networks and \acs{3D} data representations for the object classification problem. First, we proposed \emph{PointNet}: a \acl{CNN} architecture for \acs{3D} object classification which makes use of \acs{3D} representations such as point clouds or meshes by structuring them into an occupancy grid. Later, we tested an improved version under difficult conditions such as noise and occlusion to gain insight about real-world situations. We show the performance of these models and prove their suitability for real time object classification.

In Chapter \ref{cha:semseg} we performed a comprehensive review of the state of the art of semantic segmentation for image and video using deep learning techniques. We provided an useful starting point for novel researchers and also enough details and depth so that more experienced ones could find it useful. Most importantly, apart from reviewing datasets and methods, we also gathered insights about weaknesses and future research.

One of the key observations that was made after the review was the scarcity of high-quality and large-scale datasets for data-driven algorithmms learning with \ac{3D} data. Following that train of thought, Chapter \ref{cha:sim2real} introduced a novel large-scale synthetic dataset for various robotic perception tasks with special focus on 3D semantic segmentation: \emph{the RobotriX}. Together with the data, we also released the full set of tools to generate it with detailed documentation.

Finally, Chapter \ref{cha:tactile} moved to the tactile sensing topic and showed a novel \acl{GNN} architecture which is able to classify the stability of robotic grasps using humanoid hands equipped with tactile sensors whose readings are interpreted as \acs{3D} graphs. We also demonstrated that this approach exhibits better generalization capabilities than previous methods based on more traditional architectures.

\section{Limitations and Future Work}
\label{cha:conclusion:sec:future}

To conclude this thesis, there are many aspects from the works presented here that can be improved in one way or another. Apart from those limitations to address, the work done here also raises questions that might spark important future work. Here we briefly highlight both limitations and future works.

\subsection{Object Classification}

\begin{itemize}
    \item Efficient and accurate representations for 3D data: although occupancy grids have been proven useful for the object classification task, they still present a set of disadvantages which renders them unsuitable for certain situations. One of the main weaknesses of such representation is the memory footprint which causes larger models that barely fit into \ac{GPU} memory for training if a considerable resolution is requested. Alternative sparse representations such as octrees or graphs might help but they would require new architectures to process them.
    \item Real-world datasets and deployment: our work has heavily focused on developing object recognition algorithms under certain conditions (fully isolated objects and synthetic models). Although we experimented introducing real-wolrd conditions such as noise and occlusions, it is still questionable whether or not the proposed models will behave properly in the real world. It would be interesting to check if such models can be trained or at least fine-tuned with smaller scale real-world object databases to measure their generalization capability.
\end{itemize}

\subsection{Semantic Segmentation}

\begin{itemize}
    \item Update datasets and methods: deep learning evolves at the speed of light and the hotness of the topic makes it difficult to maintain an up-to-date review. Since the writing of that chapter, various works have been published: novel datasets and environments and new methods, either iterations of the already presented ones or radically new concepts.
    \item Panorama and hyperspectral segmentation: despite the thoroughness of our review, some lines were intentionally left out due to the low relevance they presented at the moment. Some of those lines are panorama and hyperspectral images segmentation, which make use of a different input rather than common \ac{RGB} images.
    \item Real-time segmentation: with the growing complexity of deep learning models, they are becoming increasingly accurate but at the same time they are becoming heavier and slower. Most works focus on increasing the accuracy rate without taking into account that such models might need to be deployed into mobile solutions to be useful in a practical application. Recent works are following this line trying to streamline segmentation models that allow for real-time implementations while keeping good accuracy.
\end{itemize}

\subsection{Simulation to Real}

\begin{itemize}
    \item Non-rigid deformations: one limitation of our dataset and the tool itself that we use to generate it is that interactions are restricted to rigid objects. Non-rigid objects are not modeled so no deformations can occur. This is a challenging problem that might increase the usefulness of the dataset and the generation tool for many other robotic manipulation tasks.
    \item Random scene generation: one of the main flaws of our dataset is the limited amount of photorealistic scenes. This is due to the difficulty of designing a plausible scene and at the same time making sure that lighting, textures, and geometries look as realistic as possible. One possible way to improve or dataset would be to devise an algorithmic approach to generate this kind of scenes.
    \item Post-processing for increased realism: recently, many works have taken advantage of \acp{GAN} to augment datasets with subtle but realistic changes. We wonder if such kind of techniques could be used to improve the realism of the renders in an adversarial manner.
    \item Real-time raytracing: with the advent of the modern \acp{GPU} which feature hardware explicitly designed for carrying out raytracing operations it would be possible to raytracing in the generation phase to make scenes look even more realistic. Apart from the integration with the engine at hand, it also implies work on the art part (texturing and illumination setup).
\end{itemize}

\subsection{Tactile Sensing}

\begin{itemize}
    \item Graph topologies for the sensor readings: although it has been proven that generating a graph representation which better represents the actual topology of the tactels in a tactile sensor is useful, an open question remains: is it there a better topology? Further experimentation can be carried out to determine that. One possible line is learning the topology itself via a neural network, e.g., a \ac{GNG} \cite{Fritzke1999}.
    \item Temporal information for dynamic grasps: our proposal was focused on detecting if a given static grasp would be stable or not. However, objects are rarely such static entities but they are rather affected by many varying forces. In that regard, a promising future line of research would investigate the possibility of adding temporal information to a graph-based architectures. A possible way to do that would integrate other common recurrent architectures for such purpose such as \acl{LSTM}.
\end{itemize}
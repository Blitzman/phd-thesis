\chapter{Sim-2-Real}

En los últimos años se ha observado un dominio cada vez mayor de las técnicas de aprendizaje profundo dirigidas a una amplia gama de problemas de visión robótica, como la comprensión de escenas, la estimación de la profundidad, la estimación del flujo óptico, el seguimiento y el agarre visual, entre otros. Estos nuevos enfoques han ido cerrando lenta pero seguramente la brecha con los tradicionales en términos de precisión y eficiencia, superándolos en más y más casos y situaciones a medida que esas nuevas técnicas maduran y se dispone de mejores datos. Un requisito clave para que estos nuevos enfoques logren una precisión sobresaliente, al mismo tiempo que son capaces de generalizar adecuadamente a situaciones no vistas, es un buen conjunto de datos. Los investigadores necesitan conjuntos de imágenes a gran escala, que sean lo suficientemente representativas para el problema en cuestión, pero que al mismo tiempo incluyan una cantidad considerable de variabilidad (además de una verdad completa del terreno para cada una de ellas, dependiendo de las necesidades del problema). En la actualidad, se carece de esos datos, ya que la generación de un conjunto de datos que satisfaga esos requisitos es difícil en la práctica debido a las dificultades inherentes a la recopilación de datos. En este capítulo, nos centramos en ese desafío y pretendemos proporcionar un punto de referencia unificado (ver Figura \ref{fig:sim2real:robotrix}) con abundantes datos para la formación, evaluación y reproducción de algoritmos y métodos sobre un amplio espectro de problemas de visión robótica.

La primera cuestión que debemos abordar es la escala. La importancia de los datos a gran escala cuando se trabaja con algoritmos de aprendizaje que requieren datos es fundamental para lograr resultados y generalización adecuados. Debido al hecho de que la recolección y etiquetado de datos del mundo real es un proceso tedioso y costoso, los entornos simulados se están volviendo cada vez más populares y se utilizan como un método para generar datos comentados de alta calidad. Sin embargo, para que un conjunto de datos sintéticos sea útil, los modelos que son entrenados usando una distribución sintética deben ser capaces de transferir ese conocimiento a un dominio de palabras reales para que sean útiles. En otras palabras, deben ser capaces de salvar la brecha de la realidad: un conjunto de discrepancias sutiles pero importantes entre los datos sintéticos y las observaciones del mundo real. El conjunto de técnicas que ayudan a salvar esa brecha pertenecen al campo de transferencia de simulación a real o simplemente \emph{sim2real}. Para ello, existen dos alternativas principales, entre otras menos populares, que han demostrado ser eficaces: o bien lograr un realismo extremo en la simulación o bien la aleatorización de dominios. El primero se centra en la generación de datos extremadamente realistas con una combinación de varias técnicas (texturas e iluminación fotorealistas, física precisa, etc.), mientras que el segundo se basa en un enfoque de adaptación de dominios que intenta generar una amplia gama de dominios de entrenamiento con variaciones aleatorias para forzar al modelo a capturar los aspectos invariables que pueden ser transferidos al dominio del mundo real. 

Otros aspectos que debemos tener en cuenta son el comportamiento físico de los sensores e intrínsecos relacionados con el vídeo, como la resolución de la imagen, la frecuencia de imagen, así como la naturaleza de cada fotograma. Varios trabajos han destacado la importancia de los datos de alta resolución y alta velocidad de fotogramas para diversas aplicaciones de visión por computador \cite{Handa2012}\cite{Held2016}. En ese sentido, nuestro objetivo es proporcionar un conjunto de datos de alta resolución con una frecuencia de imagen bastante alta (+60 FPS) y tres modalidades de datos para cada imagen: RGB-D, estéreo y 3D (nubes de puntos de colores) que simulan las particularidades de los sensores más extendidos.

Para resolver estos problemas, construimos un generador de datos sintéticos, a saber, \emph{UnrealROX}~~cite{Martinez-Gonzalez2018}, que nos permitió generar una gran cantidad de datos sintéticos. UnrealROX es un entorno extremadamente fotorealista para generar datos sintéticos para varias tareas de visión robótica. En tal entorno, un operador humano puede encarnarse, en \acl{VR}, como un agente robot dentro de una escena para que pueda navegar libremente e interactuar con los objetos como si fuera un robot del mundo real. Dicho entorno está construido sobre \ac{UE4} para aprovechar sus capacidades avanzadas de renderizado y físicas.

Proporcionar un conjunto de datos a gran escala y fotorrealista con una verdad de fondo de alta calidad es siempre muy útil para la comunidad; sin embargo, hay una serie de trabajos ya existentes que lo hacen, pero con ciertas deficiencias (baja resolución, baja velocidad de imagen, escenas algo artificiales, o modalidades escasas). Además de iterar sobre esas características para fortalecerlas, nuestro trabajo incluye un conjunto de novedosas que hacen que nuestra propuesta realmente se destaque entre la multitud:

\begin{itemize}
    \item Gran escala y nivel de fotorealismo.
    \item \emph{Frame rate} y reoslución elevados.
    \item Múltiples modalidades de datos: RGB-D/3D/Stereo.
	\item Trayectorias realistas desde varios puntos de vista.
	\item Interacción de robots con la escena y objetos.
    \item \emph{Ground truth} para diversos problemas de visión y robótica.
    \item \emph{Pipeline} y herramientas \emph{open-source}.
\end{itemize}
\chapter{Sim-2-Real}

En los últimos años se ha observado un dominio cada vez mayor de las técnicas de aprendizaje profundo dirigidas a una amplia gama de problemas de visión robótica, como la comprensión de escenas, la estimación de la profundidad, de \emph{optical flow}, \emph{tracking} y el agarre visual, entre otros. Estos nuevos enfoques han ido disminuyendo la brecha con los métodos tradicionales en términos de precisión y eficiencia, superándolos en cada vez más casos y situaciones a medida que esas nuevas técnicas maduran y se dispone de mejores datos. Un requisito clave para que estos nuevos enfoques logren una precisión sobresaliente, al mismo tiempo que son capaces de generalizar adecuadamente a situaciones no vistas, es un buen conjunto de datos. Los investigadores necesitan conjuntos de imágenes de gran escala, que sean lo suficientemente representativos para el problema en cuestión, pero que al mismo tiempo incluyan una variabilidad considerable (además de \emph{ground truth} para cada una de ellas, dependiendo de las necesidades del problema). En la actualidad, se carece de esos datos ya que la generación de un conjunto de datos que satisfaga esos requisitos es difícil en la práctica debido a las dificultades inherentes de la recopilación de datos. En este capítulo nos centramos en ese desafío y pretendemos proporcionar un punto de referencia con abundantes datos para el desarrollo, evaluación y reproducción de algoritmos y métodos en amplio espectro de problemas de visión robótica.

La primera cuestión que debemos abordar es la escala. La importancia de los datos a gran escala cuando se trabaja con algoritmos de aprendizaje que requieren datos es fundamental para lograr resultados y generalización adecuados. Debido al hecho de que la recolección y etiquetado de datos del mundo real es un proceso tedioso y costoso, los entornos simulados se están volviendo cada vez más populares y se utilizan como un método para generar datos etiquetados de alta calidad. Sin embargo, para que un conjunto de datos sintéticos sea útil, los modelos que son entrenados usando una distribución sintética deben ser capaces de transferir ese conocimiento a un dominio de datos reales. En otras palabras, deben ser capaces de salvar el conocido \emph{reality gap}: un conjunto de discrepancias sutiles pero importantes entre los datos sintéticos y las observaciones del mundo real. El conjunto de técnicas que ayudan a cerrar esa brecha pertenecen al campo de transferencia de simulación a real o simplemente \emph{sim2real}. Para ello, existen dos alternativas principales, entre otras menos populares, que han demostrado ser eficaces: o bien lograr un realismo extremo en la simulación o bien la aleatorización de dominios (\emph{domain randomization}). El primero se centra en la generación de datos extremadamente realistas con una combinación de varias técnicas (texturas e iluminación fotorealistas, física precisa, etc.), mientras que el segundo se basa en un enfoque de adaptación de dominios que intenta generar una amplia gama de dominios de entrenamiento con variaciones aleatorias para forzar al modelo a capturar los aspectos invariables que pueden ser transferidos al dominio del mundo real. 

Otros aspectos que debemos tener en cuenta son el comportamiento físico de los sensores y otras características intrínsecas relacionadas con el vídeo, como la resolución de la imagen, la frecuencia de la misma, así como la naturaleza de cada fotograma. Varios trabajos han destacado la importancia de los datos de alta resolución y alta velocidad de fotogramas para diversas aplicaciones de visión por computador \cite{Handa2012}\cite{Held2016}. En ese sentido, nuestro objetivo es proporcionar un conjunto de datos de alta resolución con una tasa de imágenes elevada (+60 FPS) y tres modalidades de datos para cada imagen: RGB-D, estéreo y 3D (nubes de puntos coloreadas) que simulan las particularidades de los sensores más extendidos.

Para resolver estos problemas, proponemos un generador de datos sintéticos, \emph{UnrealROX}~\cite{Martinez-Gonzalez2018}, que nos permite generar una gran cantidad de datos sintéticos. UnrealROX es un entorno extremadamente fotorealista para generar datos sintéticos para varias tareas de visión robótica. En tal entorno, un operador humano puede sumergirse en \acl{VR} como un agente robótico dentro de una escena y navegar libremente e interactuar con los objetos como si fuera un robot del mundo real. Dicho entorno está construido sobre \ac{UE4} para aprovechar sus capacidades avanzadas de renderizado y físicas.

Proporcionar un conjunto de datos a gran escala y fotorrealista con un \emph{ground truth} de alta calidad es siempre útil para la comunidad; sin embargo, hay una serie de trabajos ya existentes que lo hacen aunque con ciertas deficiencias (baja resolución, baja tasa de imágenes, escenas artificiales, o modalidades escasas). Además de iterar sobre esas características para fortalecerlas, nuestro trabajo incluye un conjunto de novedades que hacen que nuestra propuesta realmente destaque entre la multitud:

\begin{itemize}
    \item Gran escala y nivel de fotorealismo.
    \item \emph{Frame rate} y reoslución elevados.
    \item Múltiples modalidades de datos: RGB-D/3D/Stereo.
	\item Trayectorias realistas desde varios puntos de vista.
	\item Interacción de robots con la escena y objetos.
    \item \emph{Ground truth} para diversos problemas de visión y robótica.
    \item \emph{Pipeline} y herramientas \emph{open-source}.
\end{itemize}
\chapter{Abstract}

The care of dependent people (for reasons of aging, accidents, disabilities or illnesses) is one of the top priority lines of research for the European countries as stated in the Horizon 2020 goals. In order to minimize the cost and the intrusiveness of the therapies for care and rehabilitation, it is desired that such cares are administered at the patient's home. The natural solution for this environment is an indoor mobile robotic platform.

Such robotic platform for home care needs to solve to a certain extent a set of problems that lie in the intersection of multiple disciplines, e.g., computer vision, machine learning, and robotics. In that crossroads, one of the most notable challenges (and the one we will focus on) is scene understanding: the robot needs to understand the unstructured and dynamic environment in which it navigates and the objects with which it can interact.

In this thesis we will focus on three core tasks for full scene understanding: object class recognition, semantic segmentation, and grasp stability prediction. The first one refers to the process of categorizing an object into a set of classes (e.g., chair, bed, or pillow); the second one goes one level beyond object categorization and aims to provide a per-pixel dense labeling of each object in an image; the latter consists on determining if an object which has been grasped by a robotic hand is in a stable configuration or if it will fall.

This thesis presents contributions towards solving those three tasks using deep learning as the main tool. All those solutions share one core observation: they all rely on tridimensional data inputs to leverage that additional dimension and its spatial arrangement. The four main contributions of this thesis are: first, we show a set of architectures and data representations for 3D object classification using point clouds; secondly, we carry out an extensive review of the state of the art of semantic segmentation datasets and methods; third, we introduce a novel synthetic and large-scale photorealistic dataset for solving various robotic and vision problems together; at last, we propose a novel method and representation to deal with tactile sensors and learn to predict grasp stability.

\chapter{Resumen}

La atención a las personas dependientes (por razones de envejecimiento, accidentes, discapacidades o enfermedades) es una de las líneas de investigación prioritarias para los países europeos, tal y como se recoge en los objetivos del marco Horizonte 2020. Con el fin de minimizar el coste y la intrusividad de las terapias para el cuidado y la rehabilitación, se desea que tales cuidados sean administrados en el hogar del paciente. La solución natural para este entorno es una plataforma robótica móvil en interiores.

Esta plataforma robótica para el cuidado en el hogar necesita resolver hasta cierto punto un conjunto de problemas que se encuentran en la intersección de múltiples disciplinas, como son, la visión por computador, el aprendizaje por computadora y la robótica. En esa encrucijada, uno de los retos más notables (y en el que nos centraremos) es la comprensión de la escena: el robot necesita entender el entorno desestructurado y dinámico en el que navega y los objetos con los que puede interactuar.

Para lograr una comprensión completa de la escena, se deben realizar varias tareas. En esta tesis nos centraremos en tres de ellas: reconocimiento de la clase de objetos o \emph{object recognition}, segmentación semántica o \emph{semantic segmentation} y predicción de la estabilidad del agarre de los objetos (también denominado \emph{grasp stability prediction}). La primera se refiere al proceso de categorizar un objeto de acuerdo a un conjunto de clases (por ejemplo, silla, cama o almohada); la segunda va un nivel más allá de la categorización de objetos y tiene como objetivo proporcionar un etiquetado denso por píxel de cada objeto en una imagen; la tercera consiste en determinar si un objeto que ha sido agarrado por una mano robótica está en una configuración estable o si va a caer o deslizarse.

Esta tesis presenta contribuciones a la resolución de estas tres tareas utilizando el aprendizaje profundo (\emph{deep learning}) como la metodología principal para resolver estos problemas de reconocimiento, segmentación y predicción. Todas estas soluciones comparten una observación central: todas se basan en datos tridimensionales para aprovechar esa dimensión adicional y su disposición espacial. Las cuatro contribuciones principales de esta tesis son: en primer lugar, mostramos un conjunto de arquitecturas y representaciones de datos para la clasificación de objetos 3D utilizando nubes de puntos; en segundo lugar, llevamos a cabo una extensa revisión del estado del arte de los conjuntos de datos y métodos de segmentación semántica; en tercer lugar, introducimos un novedoso conjunto de datos sintéticos y a gran escala para la resolución conjunta de diversos problemas de robótica y visión; por último, proponemos un método y una representación alternativa para tratar con los sensores táctiles y aprender a predecir la estabilidad de agarre.
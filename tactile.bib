@article{Battaglia2018,
    title       = {Relational Inductive Biases, Deep Learning, and Graph Networks},
    author      = {Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
    journal     = {arXiv preprint arXiv:1806.01261},
    year        = {2018}
}

@article{Bruna2013,
    title       = {Spectral Networks and Locally Connected Networks on Graphs},
    author      = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
    journal     = {arXiv preprint arXiv:1312.6203},
    year        = {2013}
}

@article{Dahiya2010,
    title       = {Tactile Sensing-From Humans to Humanoids.},
    author      = {Dahiya, Ravinder S and Metta, Giorgio and Valle, Maurizio and Sandini, Giulio},
    journal     = {IEEE Transactions on Robotics},
    volume      = {26},
    number      = {1},
    pages       = {1--20},
    year        = {2010}
}

@book{Dahiya2012,
    title       = {Robotic Tactile Sensing: Technologies and System},
    author      = {Dahiya, Ravinder S and Valle, Maurizio},
    year        = {2012},
    publisher   = {Springer Science \& Business Media}
}

@inproceedings{Defferrard2016,
    title       = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
    author      = {Defferrard, Micha{\"e}l and Bresson, Xavier and Vandergheynst, Pierre},
    booktitle   = {Advances in Neural Information Processing Systems},
    pages       = {3844--3852},
    year        = {2016}
}

@article{Dhillon2007,
    title       = {Weighted graph cuts without eigenvectors a multilevel approach},
    author      = {Dhillon, Inderjit S and Guan, Yuqiang and Kulis, Brian},
    journal     = {IEEE transactions on pattern analysis and machine intelligence},
    volume      = {29},
    number      = {11},
    pages       = {1944--1957},
    year        = {2007},
    publisher   = {IEEE}
}

@inproceedings{Gilmer2017,
    title       = {Neural message passing for quantum chemistry},
    author      = {Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
    booktitle   = {Proceedings of the 34th International Conference on Machine Learning-Volume 70},
    pages       = {1263--1272},
    year        = {2017},
    organization= {JMLR. org}
}

@article{Scarselli2008,
    title       = {The Graph Neural Network Model},
    author      = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
    journal     = {IEEE Transactions on Neural Networks},
    volume      = {20},
    number      = {1},
    pages       = {61--80},
    year        = {2008},
    publisher   = {IEEE}
}

@inproceedings{su2015force,
    title       = {Force estimation and slip detection/classification for grip control using a biomimetic tactile sensor},
    author      = {Su, Zhe and Hausman, Karol and Chebotar, Yevgen and Molchanov, Artem and Loeb, Gerald E and Sukhatme, Gaurav S and Schaal, Stefan},
    booktitle   = {2015 IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids)},
    pages       = {297--303},
    year        = {2015},
    organization= {IEEE}
}

@article{Zapata2018,
    author      = {Brayan S. Zapata{-}Impata and
               Pablo Gil and
               Fernando Torres Medina},
    title       = {Non-Matrix Tactile Sensors: How Can Be Exploited Their Local Connectivity
               For Predicting Grasp Stability?},
    journal     = {IEEE/RSJ IROS 2018 Workshop RoboTac: New Progress in Tactile Perception and Learning in Robotics},
    volume      = {abs/1809.05551},
    year        = {2018},
    url         = {http://arxiv.org/abs/1809.05551},
    eprint      = {1809.05551},
    timestamp   = {Fri, 05 Oct 2018 11:34:52 +0200},
    biburl      = {https://dblp.org/rec/bib/journals/corr/abs-1809-05551},
    bibsource   = {dblp computer science bibliography, https://dblp.org}
}

@article{Zhou2018,
    title       = {Graph neural networks: A review of methods and applications},
    author      = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Sun, Maosong},
    journal     = {arXiv preprint arXiv:1812.08434},
    year        = {2018}
}






@article{Shuman2013,
  title={The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains},
  author={Shuman, David I and Narang, Sunil K and Frossard, Pascal and Ortega, Antonio and Vandergheynst, Pierre},
  journal={IEEE Signal Processing Magazine},
  volume={30},
  number={3},
  pages={83--98},
  year={2013},
  publisher={IEEE}
}

@article{Kipf2016,
  title={Semi-Supervised Classification with Graph Convolutional Networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}

@inproceedings{Jia2016,
  title={Dynamic filter networks},
  author={Jia, Xu and De Brabandere, Bert and Tuytelaars, Tinne and Gool, Luc V},
  booktitle={Advances in Neural Information Processing Systems},
  pages={667--675},
  year={2016}
}

@inproceedings{Yi2017,
  title={SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation.},
  author={Yi, Li and Su, Hao and Guo, Xingwen and Guibas, Leonidas J},
  booktitle={CVPR},
  pages={6584--6592},
  year={2017}
}

@inproceedings{Simonovsky2017,
  title={Dynamic edgeconditioned filters in convolutional neural networks on graphs},
  author={Simonovsky, Martin and Komodakis, Nikos},
  booktitle={Proc. CVPR},
  year={2017}
}

@article{Velickovic2017,
  title={Graph attention networks},
  author={Velickovic, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  volume={1},
  number={2},
  year={2017}
}

@inproceedings{Fey2018,
  title={SplineCNN: Fast geometric deep learning with continuous B-spline kernels},
  author={Fey, Matthias and Lenssen, Jan Eric and Weichert, Frank and M{\"u}ller, Heinrich},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={869--877},
  year={2018}
}

@article{Thekumparampil2018,
  title={Attention-based Graph Neural Network for Semi-supervised Learning},
  author={Thekumparampil, Kiran K and Wang, Chong and Oh, Sewoong and Li, Li-Jia},
  journal={arXiv preprint arXiv:1803.03735},
  year={2018}
}

@article{Xu2018,
  title={How Powerful are Graph Neural Networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1810.00826},
  year={2018}
}

@misc{Syntouch2018,
	author = {Syntouch},
	title = {{BioTac SP}},
	note = {https://www.syntouchinc.com/en/sensor-technology/},
	year = {2018}
}

@misc{ShadowRobotCompany2018,
	author = {{Shadow Robot Company}},
	mendeley-groups = {Robotic Grasping/Tactile Recognition,Papers/IROS18},
	title = {{Shadow Dexterous Hand}},
	note = {http://www.shadowrobot.com/products/dexterous-hand/},
	year = {2018}
}

@inproceedings{Quigley2009,
	abstract = {This paper gives an overview of ROS, an open- source robot operating system. ROS is not an operating system in the traditional sense of process management and scheduling; rather, it provides a structured communications layer above the host operating systems of a heterogenous compute cluster. In this paper, we discuss how ROS relates to existing robot software frameworks, and briefly overview some of the available application software which uses ROS.},
	author = {Quigley, Morgan and Conley, Ken and Gerkey, Brian P. and Faust, Josh and Foote, Tully and Leibs, Jeremy and Wheeler, Rob and Ng, Andrew Y.},
	booktitle = {ICRA workshop on open source software},
	number = {3.2},
	pages = {5},
	title = {{ROS: an open-source Robot Operating System}},
	volume = {3},
	year = {2009}
}

@article{Kappassov2015,
	abstract = {Tactile sensing is an essential element of autonomous dexterous robot hand manipulation. It provides information about forces of interaction and surface properties at points of contact between the robot fingers and the objects. Recent advancements in robot tactile sensing led to development of many computational techniques that exploit this important sensory channel. This paper reviews current state-of-the-art of manipulation and grasping applications that involve artificial sense of touch and discusses pros and cons of each technique. The main issues of artificial tactile sensing are addressed. General requirements of a tactile sensor are briefly discussed and the main transduction technologies are analyzed. Twenty eight various tactile sensors, each integrated into a robot hand, are classified in accordance with their transduction types and applications. Previously issued reviews are focused on hardware part of tactile sensors, whereas we present an overview of algorithms and tactile feedback-based control systems that exploit signals from the sensors. The applications of these algorithms include grasp stability estimation, tactile object recognition, tactile servoing and force control. Drawing from advancements in tactile sensing technology and taking into consideration its drawbacks, this paper outlines possible new directions of research in dexterous manipulation.},
	author = {Kappassov, Zhanat and Corrales, Juan-Antonio and Perdereau, V{\'{e}}ronique},
	doi = {10.1016/j.robot.2015.07.015},
	isbn = {0921-8890},
	issn = {09218890},
	journal = {Robotics and Autonomous Systems},
	keywords = {Dexterous manipulation,Review,Robot hands,Tactile sensing,Tactile sensing application,Tactile sensors},
	month = {dec},
	pages = {195--220},
	publisher = {Elsevier B.V.},
	title = {{Tactile sensing in dexterous robot hands â€” Review}},
	url = {http://dx.doi.org/10.1016/j.robot.2015.07.015 http://linkinghub.elsevier.com/retrieve/pii/S0921889015001621},
	volume = {74},
	year = {2015}
}

@inproceedings{Li2014b,
	abstract = {To perform robust grasping, a multi-fingered robotic hand should be able to adapt its grasping configuration, i.e., how the object is grasped, to maintain the stability of the grasp. Such a change of grasp configuration is called grasp adaptation and it depends on the controller, the employed sensory feedback and the type of uncertainties inherit to the problem. This paper proposes a grasp adaptation strategy to deal with uncertainties about physical properties of objects, such as the object weight and the friction at the contact points. Based on an object-level impedance controller, a grasp stability estimator is first learned in the object frame. Once a grasp is predicted to be unstable by the stability estimator, a grasp adaptation strategy is triggered according to the similarity between the new grasp and the training examples. Experimental results demonstrate that our method improves the grasping performance on novel objects with different physical properties from those used for training. {\textcopyright} 2014 IEEE.},
	author = {Li, Miao and Bekiroglu, Yasemin and Kragic, Danica and Billard, Aude},
	booktitle = {Intelligent Robots and Systems (IROS), 2014 IEEE/RSJ International Conference on},
	doi = {10.1109/IROS.2014.6943027},
	isbn = {978-1-4799-6934-0},
	issn = {21530866},
	month = {sep},
	pages = {3339--3346},
	publisher = {IEEE},
	title = {{Learning of grasp adaptation through experience and tactile sensing}},
	url = {http://ieeexplore.ieee.org/document/6943027/},
	year = {2014}
}

@article{Dang2014,
	abstract = {Abstract This paper deals with the problem of stable grasping under pose uncertainty . Our method utilizes tactile sensing data to estimate grasp stability and make necessary hand adjustments after an initial grasp is established. We first discuss a learning approach to ... $\backslash$n},
	author = {Dang, Hao and Allen, Peter K.},
	doi = {10.1007/s10514-013-9355-y},
	issn = {0929-5593},
	journal = {Autonomous Robots},
	keywords = {Grasping,Robustness,Tactile sensing,Uncertainty},
	month = {apr},
	number = {4},
	pages = {309--330},
	title = {{Stable grasping under pose uncertainty using tactile feedback}},
	url = {http://link.springer.com/10.1007/s10514-013-9355-y},
	volume = {36},
	year = {2014}
}

@inproceedings{Reinecke2014,
	abstract = {Dexterous manipulation of everyday objects requires a precise tactile sense. Slip detection is mandatory to overcome uncertainty and compensate for external disturbances. We compare three different approaches for detecting slip. The methods are model-based slip detection via friction cones, vibration-based detection via bandpass filtering, and a common learning algorithm. They are implemented and tested on a tendon-driven two-finger setup equipped with two tactile BioTac{\textregistered} sensors. Several experiments are conducted to evaluate each approach. The characteristics of the methods are discussed and compared.},
	author = {Reinecke, Jens and Dietrich, Alexander and Schmidt, Florian and Chalon, Maxime},
	booktitle = {Robotics and Automation (ICRA), 2014 IEEE International Conference on},
	doi = {10.1109/ICRA.2014.6907252},
	isbn = {978-1-4799-3685-4},
	issn = {10504729},
	month = {may},
	pages = {2742--2748},
	publisher = {IEEE},
	title = {{Experimental comparison of slip detection strategies by tactile sensing with the BioTac{\textregistered} on the DLR hand arm system}},
	url = {http://ieeexplore.ieee.org/document/6907252/},
	year = {2014}
}

@inproceedings{Su2015b,
	abstract = {We introduce and evaluate contact-based tech-niques to estimate tactile properties and detect manipulation events using a biomimetic tactile sensor. In particular, we estimate finger forces, and detect and classify slip events. In addition, we present a grip force controller that uses the estimation results to gently pick up objects of various weights and texture. The estimation techniques and the grip controller are experimentally evaluated on a robotic system consisting of Barrett arms and hands. Our results indicate that we are able to accurately estimate forces acting in all directions, detect the incipient slip, and classify slip with over 80{\%} success rate.},
	author = {Su, Zhe and Hausman, Karol and Chebotar, Yevgen and Molchanov, Artem and Loeb, Gerald E. and Sukhatme, Gaurav S and Schaal, Stefan},
	booktitle = {Humanoid Robots (Humanoids), 2015 IEEE-RAS 15th International Conference on},
	doi = {10.1109/HUMANOIDS.2015.7363558},
	isbn = {978-1-4799-6885-5},
	issn = {21640580},
	month = {nov},
	pages = {297--303},
	publisher = {IEEE},
	title = {{Force estimation and slip detection/classification for grip control using a biomimetic tactile sensor}},
	url = {http://ieeexplore.ieee.org/document/7363558/},
	year = {2015}
}

@inproceedings{Veiga2015,
	abstract = {â€” During grasping and other in-hand manipulation tasks maintaining a stable grip on the object is crucial for the task's outcome. Inherently connected to grip stability is the concept of slip. Slip occurs when the contact between the fingertip and the object is partially lost, resulting in sudden undesired changes to the objects state. While several approaches for slip detection have been proposed in the literature, they frequently rely on previous knowledge of the manipulated object. This previous knowledge may be unavailable, seeing that robots operating in real-world scenarios often must interact with previously unseen objects. In our work we explore the generalization capabilities of well known supervised learning methods, using random forest classifiers to create generalizable slip predictors. We utilize these classifiers in the feedback loop of an object stabilization controller. We show that the controller can successfully stabilize previously unknown objects by predicting and counteracting slip events.},
	author = {Veiga, Filipe and van Hoof, Herke and Peters, Jan and Hermans, Tucker},
	booktitle = {Intelligent Robots and Systems (IROS), 2015 IEEE/RSJ International Conference on},
	doi = {10.1109/IROS.2015.7354090},
	isbn = {978-1-4799-9994-1},
	issn = {21530866},
	month = {sep},
	pages = {5065--5072},
	publisher = {IEEE},
	title = {{Stabilizing novel objects by learning to predict tactile slip}},
	url = {http://ieeexplore.ieee.org/document/7354090/},
	volume = {2015-Decem},
	year = {2015}
}

@incollection{Meier2016a,
	abstract = {We propose a novel activation function that implements piece-wise orthogonal non-linear mappings based on permutations. It is straightforward to implement, and very computationally efficient, also it has little memory requirements. We tested it on two toy problems for feedforward and recurrent networks, it shows similar performance to tanh and ReLU. OPLU activation function ensures norm preservance of the backpropagated gradients, therefore it is potentially good for the training of deep, extra deep, and recurrent neural networks.},
	address = {Cham},
	author = {Meier, Martin and Patzelt, Florian and Haschke, Robert and Ritter, Helge J.},
	booktitle = {25th International Conference on Artificial Neural Networks},
	doi = {10.1007/978-3-319-44781-0_2},
	editor = {Villa, Alessandro E.P. and Masulli, Paolo and {Pons Rivero}, Antonio Javier},
	keywords = {Orthogonal initialization,Simple recurrent networks,Vanishing gradient effect},
	pages = {12--19},
	publisher = {Springer International Publishing},
	series = {Lecture Notes in Computer Science},
	title = {{Tactile Convolutional Networks for Online Slip and Rotation Detection}},
	url = {http://link.springer.com/10.1007/978-3-319-44781-0{\_}2},
	volume = {9887},
	year = {2016}
}

@inproceedings{Cockbum2017,
	abstract = {Abstractâ€”Grasping tasks have always been challenging for robots, despite recent innovations in vision-based algorithms and object-specific training. If robots are to match human abilities and learn to pick up never-before-seen objects, they must combine vision with tactile sensing. This paper present a novel way to improve robotic grasping: by using tactile sensors and an unsupervised feature-learning approach, a robot can find the common denominators behind successful and failed grasps, and use this knowledge to predict whether a grasp attempt will succeed or fail. This method is promising as it uses only high-level features from two tactile sensors to evaluate grasp quality, and works for the training set as well as for new objects. In total, using a total of 54 different objects, our system recognized grasp failure 83.70{\%} of time.},
	author = {Cockbum, Deen and Roberge, Jean-philippe and Le, Thuy-hong-loan and Maslyczyk, Alexis and Duchaine, Vincent},
	booktitle = {Robotics and Automation (ICRA), 2017 IEEE International Conference on},
	doi = {10.1109/ICRA.2017.7989257},
	isbn = {978-1-5090-4633-1},
	month = {may},
	pages = {2238--2244},
	publisher = {IEEE},
	title = {{Grasp stability assessment through unsupervised feature learning of tactile images}},
	url = {http://ieeexplore.ieee.org/document/7989257/},
	year = {2017}
}

@inproceedings{Kwiatkowski2017,
	abstract = {The growing demand in industry for robots ca- pable of performing a variety of tasks requires an increased capability in robotic grasping. Humans are adept at interact- ing with novel objects, a skill attributed primarily to tactile feedback in the form of exteroception and proprioception. This paper presents a novel way to incorporate exteroception and proprioception into grasp stability assessment: by using convolutional neural networks. This method improves upon the results of a unsupervised feature learning approach that used similar tactile feedback. 1000 different grasps on 100 objects were used to train and test the network. The network achieved an overall accuracy of 88.4{\%} while predicting the failure class with an accuracy of 92.7{\%}.},
	author = {Kwiatkowski, Jennifer and Cockburn, Deen and Duchaine, Vincent},
	booktitle = {Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International Conference on},
	doi = {10.1109/IROS.2017.8202170},
	isbn = {978-1-5386-2682-5},
	issn = {21530866},
	month = {sep},
	pages = {286--292},
	publisher = {IEEE},
	title = {{Grasp stability assessment through the fusion of proprioception and tactile signals using convolutional neural networks}},
	url = {http://ieeexplore.ieee.org/document/8202170/},
	year = {2017}
}

@inproceedings{Calandra2017,
	abstract = {A successful grasp requires careful balancing of the contact forces. Deducing whether a particular grasp will be successful from indirect measurements, such as vision, is therefore quite challenging, and direct sensing of contacts through touch sensing provides an appealing avenue toward more successful and consistent robotic grasping. However, in order to fully evaluate the value of touch sensing for grasp outcome prediction, we must understand how touch sensing can influence outcome prediction accuracy when combined with other modalities. Doing so using conventional model-based techniques is exceptionally difficult. In this work, we investigate the question of whether touch sensing aids in predicting grasp outcomes within a multimodal sensing framework that combines vision and touch. To that end, we collected more than 9,000 grasping trials using a two-finger gripper equipped with GelSight high-resolution tactile sensors on each finger, and evaluated visuo-tactile deep neural network models to directly predict grasp outcomes from either modality individually, and from both modalities together. Our experimental results indicate that incorporating tactile readings substantially improve grasping performance.},
	author = {Calandra, Roberto and Owens, Andrew and Upadhyaya, Manu and Yuan, Wenzhen and Lin, Justin and Adelson, Edward H. and Levine, Sergey},
	booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
	keywords = {grasping,multi-modal sensing,robot learning,tactile sensors},
	pages = {314----323},
	title = {{The Feeling of Success: Does Touch Sensing Help Predict Grasp Outcomes?}},
	url = {http://proceedings.mlr.press/v78/calandra17a.html},
	volume = {78},
	year = {2017}
}

@article{Li2018,
	abstract = {Slip detection plays a vital role in robotic manipulation and it has long been a challenging problem in the robotic community. In this paper, we propose a new method based on deep neural network (DNN) to detect slip. The training data is acquired by a GelSight tactile sensor and a camera mounted on a gripper when we use a robot arm to grasp and lift 94 daily objects with different grasping forces and grasping positions. The DNN is trained to classify whether a slip occurred or not. To evaluate the performance of the DNN, we test 10 unseen objects in 152 grasps. A detection accuracy as high as 88.03{\%} is achieved. It is anticipated that the accuracy can be further improved with a larger dataset. This method is beneficial for robots to make stable grasps, which can be widely applied to automatic force control, grasping strategy selection and fine manipulation.},
	archivePrefix = {arXiv},
	arxivId = {1802.10153},
	author = {Li, Jianhua and Dong, Siyuan and Adelson, Edward},
	eprint = {1802.10153},
	isbn = {9781538630808},
	title = {{Slip Detection with Combined Tactile and Visual Information}},
	url = {http://arxiv.org/abs/1802.10153},
	year = {2018}
}

@article{Zhang2018,
	abstract = {Tactile sensing is essential to the human perception system, so as to robot. In this paper, we develop a novel optical-based tactile sensor "FingerVision" with effective signal processing algorithms. This sensor is composed of soft skin with embedded marker array bonded to rigid frame, and a web camera with a fisheye lens. While being excited with contact force, the camera tracks the movements of markers and deformation field is obtained. Compared to existing tactile sensors, our sensor features compact footprint, high resolution, and ease of fabrication. Besides, utilizing the deformation field estimation, we propose a slip classification framework based on convolution Long Short Term Memory (convolutional LSTM) networks. The data collection process takes advantage of the human sense of slip, during which human hand holds 12 daily objects, interacts with sensor skin and labels data with a slip or non-slip identity based on human feeling of slip. Our slip classification framework performs high accuracy of 97.62{\%} on the test dataset. It is expected to be capable of enhancing the stability of robot grasping significantly, leading to better contact force control, finer object interaction and more active sensing manipulation.},
	archivePrefix = {arXiv},
	arxivId = {1810.02653},
	author = {Zhang, Yazhan and Kan, Zicheng and Tse, Yu Alexander and Yang, Yang and Wang, Michael Yu},
	eprint = {1810.02653},
	title = {{FingerVision Tactile Sensor Design and Slip Detection Using Convolutional LSTM Network}},
	url = {http://arxiv.org/abs/1810.02653},
	year = {2018}
}

@inproceedings{Schlichtkrull2018,
  title={Modeling relational data with graph convolutional networks},
  author={Schlichtkrull, Michael and Kipf, Thomas N and Bloem, Peter and van den Berg, Rianne and Titov, Ivan and Welling, Max},
  booktitle={European Semantic Web Conference},
  pages={593--607},
  year={2018},
  organization={Springer}
}

@article{Bronstein2017,
  title={Geometric deep learning: going beyond euclidean data},
  author={Bronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={4},
  pages={18--42},
  year={2017},
  publisher={IEEE}
}

@inproceedings{Chebotar2016bigs,
	author = {Chebotar, Yevgen and Hausman, Karol and Su, Zhe and Molchanov, Artem and Kroemer, Oliver and Sukhatme, Gaurav and Schaal, Stefan},
	booktitle = {ICRA 2016 Workshop on Grasping and Manipulation Datasets},
	doi = {10.1038/nrn2621.},
	title = {{BiGS: BioTac Grasp Stability Dataset}},
	year = {2016}
}

@incollection{Fritzke1999,
  title={Growing self-organizing networksâ€”history, status quo, and perspectives},
  author={Fritzke, Bernd},
  booktitle={Kohonen Maps},
  pages={131--144},
  year={1999},
  publisher={Elsevier}
}
